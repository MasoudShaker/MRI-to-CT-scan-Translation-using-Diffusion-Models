{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "from diffusion import loss_fn, marginal_prob_std, diffusion_coeff, EMA, euler_sampler, pc_sampler, ode_sampler\n",
    "from utils import get_ssim, get_psnr, get_mse, get_mae, save_best_samples, save_metrics, pre_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4374, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'mr_train_resized.hdf5'\n",
    "f = h5py.File(path,'r')\n",
    "mr_train = f['data']\n",
    "\n",
    "path = 'mr_test_resized.hdf5'\n",
    "f = h5py.File(path,'r')\n",
    "mr_test = f['data']\n",
    "\n",
    "train_size = mr_train.shape[0]\n",
    "test_size = mr_test.shape[0]\n",
    "\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"data\": shape (81, 128, 128), type \"<f4\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'ct_test_resized.hdf5'\n",
    "f = h5py.File(path,'r')\n",
    "ct_test = f['data']\n",
    "\n",
    "ct_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import scipy.io as sio\n",
    "# from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import functools\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Train_Data, Test_Data\n",
    "from diffusion import ode_sampler, euler_sampler, pc_sampler\n",
    "from model import UNet\n",
    "\n",
    "\n",
    "train = True\n",
    "continue_train = False\n",
    "\n",
    "# UNet\n",
    "ch = 64\n",
    "ch_mult = [1, 2, 2, 4, 4]\n",
    "attn = [1]\n",
    "num_res_blocks = 2\n",
    "dropout = 0.\n",
    "\n",
    "# Gaussian Diffusion\n",
    "beta_1 = 1e-4\n",
    "beta_T = 0.02\n",
    "T = 1000\n",
    "\n",
    "# Training\n",
    "lr = 1e-4\n",
    "grad_clip = 1.\n",
    "img_size = 128\n",
    "batch_size = 2\n",
    "num_workers = 1\n",
    "ema_decay = 0.9999\n",
    "\n",
    "sample_size = 1\n",
    "\n",
    "min_epoch = 100\n",
    "max_epoch = 110\n",
    "\n",
    "epoch_mean_loss = max_epoch * [None]\n",
    "n_prev_epochs = 20\n",
    "\n",
    "DIREC = f'score-unet_min-epoch_{min_epoch}_n-train-samples_{train_size}n-test-samples_{test_size}_batch-size_{batch_size}_T_{T}_img-size_{img_size}_data_augmentation_all'\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "\n",
    "    sigma = 25.\n",
    "    marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma) # construc function without parameters\n",
    "    diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma) # construc function without parameters\n",
    "\n",
    "    # dataset\n",
    "    train_data = Train_Data()\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=num_workers,\n",
    "                             pin_memory=True, shuffle=True)\n",
    "\n",
    "    # model setup\n",
    "    score_model = UNet(T=T, ch=ch, ch_mult=ch_mult, attn=attn,\n",
    "                       num_res_blocks=num_res_blocks, dropout=dropout,\n",
    "                       marginal_prob_std=marginal_prob_std_fn).to(device)\n",
    "\n",
    "    ema_model = EMA(score_model).to(device)\n",
    "\n",
    "    optim = torch.optim.Adam(score_model.parameters(), lr=lr)\n",
    "\n",
    "    # show model size\n",
    "    model_size = 0\n",
    "    for param in score_model.parameters():\n",
    "        model_size += param.data.nelement()\n",
    "    print('Model params: %.2f M' % (model_size / 1024 / 1024))\n",
    "\n",
    "\n",
    "    if not os.path.exists('current experiment'):\n",
    "        os.makedirs('current experiment')\n",
    "\n",
    "    if not os.path.exists('./current experiment/Saved_model'):\n",
    "        os.makedirs('./current experiment/Saved_model')\n",
    "\n",
    "    last_epoch = False\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            tmp_tr_loss = 0\n",
    "            tr_sample = 0\n",
    "            score_model.train()\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "                # train\n",
    "                condition = data.to(device)\n",
    "                x_0 = target.to(device)\n",
    "\n",
    "                loss = loss_fn(score_model, condition, x_0, marginal_prob_std_fn)\n",
    "\n",
    "                tmp_tr_loss += loss.item()\n",
    "                tr_sample += len(data)\n",
    "\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                ema_model.update(score_model)\n",
    "\n",
    "                tepoch.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "        mean_loss = tmp_tr_loss / tr_sample\n",
    "        print('mean loss:', mean_loss)\n",
    "\n",
    "        epoch_mean_loss[epoch] = mean_loss\n",
    "        \n",
    "        if epoch+1 > min_epoch:\n",
    "          prev_mean_loss = 0\n",
    "          \n",
    "          for i in range(n_prev_epochs):\n",
    "            prev_mean_loss += epoch_mean_loss[epoch - (i+1)]\n",
    "\n",
    "          prev_mean_loss /= n_prev_epochs\n",
    "          \n",
    "          if mean_loss > (prev_mean_loss - 0.01*prev_mean_loss):\n",
    "            break\n",
    "\n",
    "    torch.save(score_model.state_dict(), f'./current experiment/Saved_model/score-unet_epoch_{epoch+1}.pt')\n",
    "\n",
    "    return epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch_num = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sampler_type):\n",
    "    \n",
    "    if not os.path.exists(f'./current experiment/Train_Output_{sampler_type}/' + DIREC):\n",
    "        os.makedirs(f'./current experiment/Train_Output_{sampler_type}/' + DIREC)\n",
    "\n",
    "    if not os.path.exists(f'./current experiment/diff_results_{sampler_type}'):\n",
    "        os.makedirs(f'./current experiment/diff_results_{sampler_type}')\n",
    "\n",
    "    sigma = 25.\n",
    "    sum_time = 0\n",
    "\n",
    "\n",
    "    marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma) # construc function without parameters\n",
    "    diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma) # construc function without parameters\n",
    "\n",
    "\n",
    "    test_data = Test_Data()\n",
    "    test_loader = DataLoader(test_data, batch_size=sample_size, num_workers=num_workers,\n",
    "                             pin_memory=True, shuffle=False)\n",
    "    \n",
    "    score_model = UNet(T=T, ch=ch, ch_mult=ch_mult, attn=attn,\n",
    "                    num_res_blocks=num_res_blocks, dropout=dropout,\n",
    "                    marginal_prob_std=marginal_prob_std_fn).to(device)\n",
    "\n",
    "    # ema_model = EMA(score_model).to(device)\n",
    "\n",
    "    model_path = f'./current experiment/Saved_model/score-unet_epoch_{last_epoch_num}.pt'\n",
    "\n",
    "    score_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "    if sampler_type == 'od':\n",
    "        sampler = ode_sampler\n",
    "    elif sampler_type == 'eu':\n",
    "        sampler = euler_sampler\n",
    "    elif sampler_type == 'pc':\n",
    "        sampler = pc_sampler\n",
    "    else:\n",
    "        print('unvaild value for sampler. valid values: od, eu, pc')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(test_loader):\n",
    "                condition = data.to(device)\n",
    "\n",
    "                tic = time.time()\n",
    "                samples = sampler(score_model, condition, marginal_prob_std_fn, diffusion_coeff_fn, sample_size)\n",
    "                toc = time.time()\n",
    "                time_interval = toc - tic\n",
    "                sum_time += time_interval\n",
    "\n",
    "                diff_out = np.array(samples.cpu())\n",
    "                save_path = f'./current experiment/diff_results_{sampler_type}/x0_number_{idx+1}_epoch_{last_epoch_num}.npy'\n",
    "                np.save(save_path, diff_out)\n",
    "                # sample visulization\n",
    "                samples = samples.clamp(0., 1.)\n",
    "\n",
    "                fig = plt.figure()\n",
    "                fig.set_figheight(4)\n",
    "                fig.set_figwidth(20)\n",
    "                spec = gridspec.GridSpec(ncols=3, nrows=1,\n",
    "                                        width_ratios=[1,1,1], wspace=0.01,\n",
    "                                        hspace=0.01, height_ratios=[1],left=0,right=1,top=1,bottom=0)\n",
    "                ax = fig.add_subplot(spec[0])\n",
    "                ax.imshow(data[0].data.squeeze().cpu(), cmap='gray', vmin=0, vmax=1)\n",
    "                ax.axis('off')\n",
    "\n",
    "                ax = fig.add_subplot(spec[1])\n",
    "                ax.imshow(samples[0].squeeze().cpu(), cmap='gray', vmin=0, vmax=1)\n",
    "                ax.axis('off')\n",
    "            \n",
    "                ax = fig.add_subplot(spec[2])\n",
    "                ax.imshow(target[0].data.squeeze().cpu(), cmap='gray', vmin=0, vmax=1)\n",
    "                ax.axis('off')\n",
    "\n",
    "\n",
    "                plt.savefig(f'./current experiment/Train_Output_{sampler_type}/'+ DIREC + '/sample_' + str(idx) + '.png',\n",
    "                            bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "                plt.close()\n",
    "                \n",
    "\n",
    "\n",
    "    return sum_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_sum_time = test(sampler_type='od')\n",
    "eu_sum_time = test(sampler_type='eu')\n",
    "pc_sum_time = test(sampler_type='pc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# od_sum_time = 536.8354086875916\n",
    "# eu_sum_time = 1018.3237380981445\n",
    "pc_sum_time = 12047.802762508392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.73830570998015"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_time = od_sum_time / test_size\n",
    "# avg_time = eu_sum_time / test_size\n",
    "avg_time = pc_sum_time / test_size\n",
    "avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_outs = [None] * test_size\n",
    "sampler_type = 'pc'\n",
    "last_epoch_num = 101\n",
    "\n",
    "for i in range(test_size):\n",
    "\n",
    "  path = f'./current experiment/diff_results_{sampler_type}/x0_number_{i+1}_epoch_{last_epoch_num}.npy'\n",
    "  diff_out = np.load(path)\n",
    "  diff_outs[i] = pre_process(diff_out, img_size).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [None] * test_size\n",
    "\n",
    "for i in range(test_size):\n",
    "  ct_sample = ct_test[i]\n",
    "  targets[i] = pre_process(ct_sample, img_size).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ssim, argmax_ssim, avg_ssim = get_ssim(diff_outs, targets)\n",
    "max_psnr, argmax_psnr, avg_psnr = get_psnr(diff_outs, targets)\n",
    "\n",
    "min_mse, argmin_mse, avg_mse = get_mse(diff_outs, targets)\n",
    "min_mae, argmin_mae, avg_mae = get_mae(diff_outs, targets)\n",
    "\n",
    "save_best_samples(sampler_type, DIREC, diff_outs, targets, argmax_ssim, argmax_psnr, argmin_mse, argmin_mae)\n",
    "save_metrics(sampler_type, avg_time, avg_ssim, avg_psnr, avg_mse, avg_mae, max_ssim, max_psnr, min_mse, min_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
