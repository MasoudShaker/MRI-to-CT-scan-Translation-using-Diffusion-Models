{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKN-smtoWI0o",
        "outputId": "8869dfa4-f3ff-44fa-9a49-8f9bdf9dc928"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hu1FkX2GV6hh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W8hqNuktV6hk",
        "outputId": "c93c2b9e-63ba-49e6-db35-f47bd1ea460e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9X2-UMZKV6hl"
      },
      "outputs": [],
      "source": [
        "# read mr and ct datasets\n",
        "MR_train_address = 'drive/MyDrive/MR_CT_data/train_input.npy'\n",
        "CT_train_address = 'drive/MyDrive/MR_CT_data/train_output.npy'\n",
        "\n",
        "MR_val_address = 'drive/MyDrive/MR_CT_data/val_input.npy'\n",
        "CT_val_address = 'drive/MyDrive/MR_CT_data/val_output.npy'\n",
        "\n",
        "MR_test_address = 'drive/MyDrive/MR_CT_data/test_input.npy'\n",
        "CT_test_address = 'drive/MyDrive/MR_CT_data/test_output.npy'\n",
        "\n",
        "mr_train = np.load(MR_train_address)\n",
        "ct_train = np.load(CT_train_address)\n",
        "\n",
        "mr_val = np.load(MR_val_address)\n",
        "ct_val = np.load(CT_val_address)\n",
        "\n",
        "mr_test = np.load(MR_test_address)\n",
        "ct_test = np.load(CT_test_address)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-7AfMLQ1V6hn"
      },
      "outputs": [],
      "source": [
        "# resizes a 1d numpy array to an arbitrary size\n",
        "def resize(img, size):\n",
        "\n",
        "  img = img.astype('float32')\n",
        "  img = torch.tensor(img)\n",
        "  img = img.unsqueeze(0)\n",
        "\n",
        "  transform = T.Resize(size)\n",
        "  resized_img = transform(img)\n",
        "\n",
        "  # resized_img = np.array(resized_img)\n",
        "\n",
        "  return resized_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6tpQFhr5V6ho"
      },
      "outputs": [],
      "source": [
        "change_gray_level = T.Compose([\n",
        "    T.Lambda(lambda t: t * 0.2)\n",
        "])\n",
        "\n",
        "horizontal_flip = T.Compose([\n",
        "    T.functional.hflip\n",
        "])\n",
        "\n",
        "vertical_flip = T.Compose([\n",
        "    T.functional.vflip\n",
        "])\n",
        "\n",
        "rotate_45 = T.Compose([\n",
        "    T.Lambda(lambda t: T.functional.rotate(t, angle=45))\n",
        "])\n",
        "\n",
        "rotate_minus_45 = T.Compose([\n",
        "    T.Lambda(lambda t: T.functional.rotate(t, angle=-45))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nFWQIvk_V6ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7686a75f-3643-4128-c8c7-9746da0b09e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "n_train_samples = ct_train.shape[0]\n",
        "n_val_samples = ct_val.shape[0]\n",
        "n_test_samples = ct_test.shape[0]\n",
        "\n",
        "# remove 90 samples from test data and add it to train data\n",
        "n_add_from_test_to_train = 150\n",
        "\n",
        "n_train_new = n_train_samples + n_val_samples + n_add_from_test_to_train\n",
        "n_test_new = n_test_samples - n_add_from_test_to_train\n",
        "\n",
        "# data augmentation\n",
        "# add 5 varient of each sample\n",
        "# so our train dataset will be 6 times bigger\n",
        "\n",
        "# n_train_new = n_train_new * 6\n",
        "# n_train_new = n_train_new * 3\n",
        "# n_train_new = n_train_new * 2\n",
        "\n",
        "mr_train_resized = [None] * n_train_new\n",
        "ct_train_resized = [None] * n_train_new\n",
        "\n",
        "mr_test_resized = [None] * n_test_new\n",
        "ct_test_resized = [None] * n_test_new\n",
        "\n",
        "# train samples with augmentation\n",
        "for i in range(n_train_samples):\n",
        "\n",
        "#   j = i * 6\n",
        "  # j = i*3\n",
        "  j = i\n",
        "  # j = i*2\n",
        "\n",
        "  resized_mr = resize(mr_train[i], 128)\n",
        "\n",
        "  mr_train_resized[j] = resized_mr\n",
        "  # mr_train_resized[j+1] = change_gray_level(resized_mr)\n",
        "  # mr_train_resized[j+1] = horizontal_flip(resized_mr)\n",
        "  # mr_train_resized[j+2] = vertical_flip(resized_mr)\n",
        "  # mr_train_resized[j+1] = rotate_45(resized_mr)\n",
        "  # mr_train_resized[j+2] = rotate_minus_45(resized_mr)\n",
        "\n",
        "  resized_ct = resize(ct_train[i], 128)\n",
        "\n",
        "  ct_train_resized[j] = resized_ct\n",
        "  # ct_train_resized[j+1] = change_gray_level(resized_ct)\n",
        "  # ct_train_resized[j+1] = horizontal_flip(resized_ct)\n",
        "  # ct_train_resized[j+2] = vertical_flip(resized_ct)\n",
        "  # ct_train_resized[j+1] = rotate_45(resized_ct)\n",
        "  # ct_train_resized[j+2] = rotate_minus_45(resized_ct)\n",
        "\n",
        "\n",
        "# validation samples with augmentation\n",
        "for i in range(n_val_samples):\n",
        "\n",
        "#   j = i*6 + n_train_samples*6\n",
        "  # j = i*3 + n_train_samples*3\n",
        "  j = i + n_train_samples\n",
        "  # j = i*2 + n_train_samples*2\n",
        "\n",
        "  resized_mr = resize(mr_val[i], 128)\n",
        "\n",
        "  mr_train_resized[j] = resized_mr\n",
        "  # mr_train_resized[j+1] = change_gray_level(resized_mr)\n",
        "  # mr_train_resized[j+1] = horizontal_flip(resized_mr)\n",
        "  # mr_train_resized[j+2] = vertical_flip(resized_mr)\n",
        "  # mr_train_resized[j+1] = rotate_45(resized_mr)\n",
        "  # mr_train_resized[j+2] = rotate_minus_45(resized_mr)\n",
        "\n",
        "  resized_ct = resize(ct_val[i], 128)\n",
        "\n",
        "  ct_train_resized[j] = resized_ct\n",
        "  # ct_train_resized[j+1] = change_gray_level(resized_ct)\n",
        "  # ct_train_resized[j+1] = horizontal_flip(resized_ct)\n",
        "  # ct_train_resized[j+2] = vertical_flip(resized_ct)\n",
        "  # ct_train_resized[j+1] = rotate_45(resized_ct)\n",
        "  # ct_train_resized[j+2] = rotate_minus_45(resized_ct)\n",
        "\n",
        "\n",
        "# part of test samples with augmentation\n",
        "\n",
        "for i in range(n_add_from_test_to_train):\n",
        "\n",
        "#   j = i*6 + n_train_samples*6 + n_val_samples*6\n",
        "  # j = i*3 + n_train_samples*3 + n_val_samples*3\n",
        "  # j = i + n_train_samples + n_val_samples\n",
        "  j = i + n_train_samples + n_val_samples\n",
        "  # j = i + n_train_samples*2 + n_val_samples*2\n",
        "\n",
        "  resized_mr = resize(mr_test[i], 128)\n",
        "\n",
        "  mr_train_resized[j] = resized_mr\n",
        "  # mr_train_resized[j+1] = change_gray_level(resized_mr)\n",
        "  # mr_train_resized[j+1] = horizontal_flip(resized_mr)\n",
        "  # mr_train_resized[j+2] = vertical_flip(resized_mr)\n",
        "  # mr_train_resized[j+1] = rotate_45(resized_mr)\n",
        "  # mr_train_resized[j+2] = rotate_minus_45(resized_mr)\n",
        "\n",
        "  resized_ct = resize(ct_test[i], 128)\n",
        "\n",
        "  ct_train_resized[j] = resized_ct\n",
        "  # ct_train_resized[j+1] = change_gray_level(resized_ct)\n",
        "  # ct_train_resized[j+1] = horizontal_flip(resized_ct)\n",
        "  # ct_train_resized[j+2] = vertical_flip(resized_ct)\n",
        "  # ct_train_resized[j+1] = rotate_45(resized_ct)\n",
        "  # ct_train_resized[j+2] = rotate_minus_45(resized_ct)\n",
        "\n",
        "# test samples\n",
        "for i in range(n_test_new):\n",
        "\n",
        "  j = i + n_add_from_test_to_train\n",
        "\n",
        "  mr_test_resized[i] = resize(mr_test[j], 128)\n",
        "  ct_test_resized[i] = resize(ct_test[j], 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xq2mUaRNV6hp"
      },
      "outputs": [],
      "source": [
        "# convert train and test samples to numpy array\n",
        "for i in range(n_train_new):\n",
        "  mr_train_resized[i] = np.array(mr_train_resized[i].squeeze())\n",
        "  ct_train_resized[i] = np.array(ct_train_resized[i].squeeze())\n",
        "\n",
        "for i in range(n_test_new):\n",
        "  mr_test_resized[i] = np.array(mr_test_resized[i].squeeze())\n",
        "  ct_test_resized[i] = np.array(ct_test_resized[i].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1Ii4iGXtV6hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2236bb1d-80db-4abc-d453-a2717ae80946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train images shape: (810, 128, 128)\n",
            "test images shape: (0,)\n"
          ]
        }
      ],
      "source": [
        "# convert lists of mr and ct to numpy arrays\n",
        "mr_train_resized = np.array(mr_train_resized)\n",
        "\n",
        "ct_train_resized = np.array(ct_train_resized)\n",
        "\n",
        "mr_test_resized = np.array(mr_test_resized)\n",
        "\n",
        "ct_test_resized = np.array(ct_test_resized)\n",
        "\n",
        "\n",
        "print('train images shape:', mr_train_resized.shape)\n",
        "print('test images shape:', mr_test_resized.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "k = 81\n",
        "fold_size = int(n_train_new / k)\n",
        "\n",
        "mr_train_all_folds = ()\n",
        "ct_train_all_folds = ()\n",
        "\n",
        "for i in range(k):\n",
        "\n",
        "  mr_fold = mr_train_resized[i*fold_size:(i+1)*fold_size]\n",
        "  ct_fold = ct_train_resized[i*fold_size:(i+1)*fold_size]\n",
        "\n",
        "  with h5py.File(f'mr_test{i+1}.hdf5', 'w') as f:\n",
        "    dset = f.create_dataset(\"data\", data = mr_fold)\n",
        "\n",
        "  with h5py.File(f'ct_test{i+1}.hdf5', 'w') as f:\n",
        "      dset = f.create_dataset(\"data\", data = ct_fold)\n",
        "\n",
        "  mr_train_all_folds += (mr_fold,)\n",
        "  ct_train_all_folds += (ct_fold,)"
      ],
      "metadata": {
        "id": "0Gfi1MNQaxyx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(k):\n",
        "\n",
        "  mr_train_all_folds_lst = list(mr_train_all_folds)\n",
        "  ct_train_all_folds_lst = list(ct_train_all_folds)\n",
        "\n",
        "  mr_train_all_folds_lst.pop(i)\n",
        "  ct_train_all_folds_lst.pop(i)\n",
        "\n",
        "  mr_train = tuple(mr_train_all_folds_lst)\n",
        "  ct_train = tuple(ct_train_all_folds_lst)\n",
        "\n",
        "  mr_train = np.vstack(mr_train)\n",
        "  ct_train = np.vstack(ct_train)\n",
        "\n",
        "  with h5py.File(f'mr_train{i+1}.hdf5', 'w') as f:\n",
        "    dset = f.create_dataset(\"data\", data = mr_train)\n",
        "\n",
        "  with h5py.File(f'ct_train{i+1}.hdf5', 'w') as f:\n",
        "      dset = f.create_dataset(\"data\", data = ct_train)"
      ],
      "metadata": {
        "id": "5Wc8hWaUcuZB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q46jjiaHV6hr"
      },
      "outputs": [],
      "source": [
        "# perform data augmentation on training data with fold number specified\n",
        "def augment(fold):\n",
        "\n",
        "  mr_path = f'mr_train{fold}.hdf5'\n",
        "  f = h5py.File(mr_path,'r')\n",
        "  mr_data = f['data']\n",
        "  n_mr_samples = len(mr_data)\n",
        "\n",
        "  ct_path = f'ct_train{fold}.hdf5'\n",
        "  f = h5py.File(ct_path,'r')\n",
        "  ct_data = f['data']\n",
        "  n_ct_samples = len(ct_data)\n",
        "\n",
        "  mr_augmented = [None] * n_mr_samples*2\n",
        "  ct_augmented = [None] * n_ct_samples*2\n",
        "\n",
        "  for i in range(n_mr_samples):\n",
        "\n",
        "    j = i*2\n",
        "\n",
        "    mr_sample = mr_data[i]\n",
        "    mr_augmented[j] = mr_sample\n",
        "    mr_augmented[j+1] = change_gray_level(mr_sample)\n",
        "\n",
        "    ct_sample = ct_data[i]\n",
        "    ct_augmented[j] = ct_sample\n",
        "    ct_augmented[j+1] = change_gray_level(ct_sample)\n",
        "\n",
        "\n",
        "  with h5py.File(f'mr_train_augmented{fold}.hdf5', 'w') as f:\n",
        "      dset = f.create_dataset(\"data\", data = mr_augmented)\n",
        "\n",
        "  with h5py.File(f'ct_train_augmented{fold}.hdf5', 'w') as f:\n",
        "      dset = f.create_dataset(\"data\", data = ct_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augment(fold=1)"
      ],
      "metadata": {
        "id": "mAMFZKrwfJB5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8B4_qXHSV6hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3500f417-b50f-4d82-a955-cf7b30df4dfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "path = 'ct_train_augmented1.hdf5'\n",
        "f = h5py.File(path,'r')\n",
        "load_data = f['data']\n",
        "# plt.imshow(load_data[0], cmap='gray')\n",
        "(load_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NZ81LSbeV6ht"
      },
      "outputs": [],
      "source": [
        "# dataset.py DDPM folder\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "def random_rot(img1,img2):\n",
        "    k = np.random.randint(0, 3)\n",
        "    img1 = np.rot90(img1, k+1)\n",
        "    img2 = np.rot90(img2, k+1)\n",
        "    return img1,img2\n",
        "\n",
        "def random_flip(img1,img2):\n",
        "    axis = np.random.randint(0, 2)\n",
        "    img1 = np.flip(img1, axis=axis).copy()\n",
        "    img2 = np.flip(img2, axis=axis).copy()\n",
        "    return img1,img2\n",
        "\n",
        "class RandomGenerator(object):\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        lr, hr = sample['lr'], sample['hr']\n",
        "\n",
        "        if random.random() > 0.5:\n",
        "            lr, hr = random_rot(lr, hr)\n",
        "        if random.random() > 0.5:\n",
        "            lr, hr = random_flip(lr, hr)\n",
        "        sample = {'lr': lr,'hr': hr}\n",
        "        return sample\n",
        "\n",
        "\n",
        "\n",
        "class Train_Data(Dataset):\n",
        "    def __init__(self, mr_path, ct_path):\n",
        "        path = mr_path\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.lr = load_data\n",
        "        path = ct_path\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.hr = load_data\n",
        "        c, self.h, self.w = self.lr.shape\n",
        "\n",
        "        self.len = c\n",
        "        self.transform=transforms.Compose([RandomGenerator(output_size=[self.h, self.w])])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.lr[index, :, :]\n",
        "        y = self.hr[index, :, :]\n",
        "\n",
        "        x = self.norm(x)\n",
        "        y = self.norm(y)\n",
        "\n",
        "        sample = {'lr': x,'hr': y}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        x, y = sample['lr'], sample['hr']\n",
        "\n",
        "        xx = np.zeros((1, self.h, self.w))\n",
        "        yy = np.zeros((1, self.h, self.w))\n",
        "\n",
        "        xx[0,:,:] = x.copy()\n",
        "        yy[0,:,:] = y.copy()\n",
        "\n",
        "        xx = torch.from_numpy(xx)\n",
        "        yy = torch.from_numpy(yy)\n",
        "\n",
        "        xx = xx.type(torch.FloatTensor)\n",
        "        yy = yy.type(torch.FloatTensor)\n",
        "\n",
        "        return xx, yy\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def norm(self, x):\n",
        "        if np.amax(x) > 0:\n",
        "            x = (x - np.amin(x)) / (np.amax(x) - np.amin(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class Valid_Data(Dataset):\n",
        "    def __init__(self, mr_path, ct_path):\n",
        "        path = mr_path\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.lr = load_data\n",
        "        path = ct_path\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.hr = load_data\n",
        "        c, self.h, self.w = self.lr.shape\n",
        "\n",
        "        self.len = c\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.lr[index, :, :]\n",
        "        y = self.hr[index, :, :]\n",
        "\n",
        "        x = self.norm(x)\n",
        "        y = self.norm(y)\n",
        "\n",
        "        xx = np.zeros((1, self.h, self.w))\n",
        "        yy = np.zeros((1, self.h, self.w))\n",
        "\n",
        "        xx[0,:,:] = x.copy()\n",
        "        yy[0,:,:] = y.copy()\n",
        "\n",
        "        xx = torch.from_numpy(xx)\n",
        "        yy = torch.from_numpy(yy)\n",
        "\n",
        "        xx = xx.type(torch.FloatTensor)\n",
        "        yy = yy.type(torch.FloatTensor)\n",
        "\n",
        "        return xx, yy\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def norm(self, x):\n",
        "        if np.amax(x) > 0:\n",
        "            x = (x - np.amin(x)) / (np.amax(x) - np.amin(x))\n",
        "        return x\n",
        "\n",
        "class Test_Data(Dataset):\n",
        "    def __init__(self):\n",
        "        path = '/path/to/test_mri_data'\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.lr = load_data\n",
        "        path = '/path/to/test_ct_data'\n",
        "        f = h5py.File(path,'r')\n",
        "        load_data = f['data']\n",
        "        self.hr = load_data\n",
        "        c, self.h, self.w = self.lr.shape\n",
        "\n",
        "        self.len = 135\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.lr[index, :, :]\n",
        "        y = self.hr[index, :, :]\n",
        "\n",
        "        x = self.norm(x)\n",
        "        y = self.norm(y)\n",
        "\n",
        "        xx = np.zeros((1, self.h, self.w))\n",
        "        yy = np.zeros((1, self.h, self.w))\n",
        "\n",
        "        xx[0,:,:] = x.copy()\n",
        "        yy[0,:,:] = y.copy()\n",
        "\n",
        "        xx = torch.from_numpy(xx)\n",
        "        yy = torch.from_numpy(yy)\n",
        "\n",
        "        xx = xx.type(torch.FloatTensor)\n",
        "        yy = yy.type(torch.FloatTensor)\n",
        "\n",
        "        return xx, yy\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def norm(self, x):\n",
        "        if np.amax(x) > 0:\n",
        "            x = (x - np.amin(x)) / (np.amax(x) - np.amin(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-qbh_0G7V6ht"
      },
      "outputs": [],
      "source": [
        "# diffusion.py DDPM folder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def extract(v, t, x_shape):\n",
        "    \"\"\"\n",
        "    Extract some coefficients at specified timesteps, then reshape to\n",
        "    [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
        "    \"\"\"\n",
        "    out = torch.gather(v, index=t, dim=0).float()\n",
        "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
        "\n",
        "\n",
        "class GaussianDiffusionTrainer(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "\n",
        "        self.register_buffer(\n",
        "            'betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer(\n",
        "            'sqrt_alphas_bar', torch.sqrt(alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))\n",
        "\n",
        "    def forward(self, x_0, condition):\n",
        "        \"\"\"\n",
        "        Algorithm 1.\n",
        "        \"\"\"\n",
        "        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)\n",
        "        noise = torch.randn_like(x_0)\n",
        "        x_t = (\n",
        "            extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 +\n",
        "            extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise)\n",
        "\n",
        "        x_recon = self.model(torch.cat([x_t, condition], dim=1), t)\n",
        "\n",
        "        loss = F.mse_loss(x_recon, noise, reduction='none').mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class GaussianDiffusionSampler(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T, img_size=32,\n",
        "                 mean_type='epsilon', var_type='fixedlarge'):\n",
        "        assert mean_type in ['xprev' 'xstart', 'epsilon']\n",
        "        assert var_type in ['fixedlarge', 'fixedsmall']\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "        self.img_size = img_size\n",
        "        self.mean_type = mean_type\n",
        "        self.var_type = var_type\n",
        "\n",
        "        self.register_buffer(\n",
        "            'betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer(\n",
        "            'sqrt_recip_alphas_bar', torch.sqrt(1. / alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'sqrt_recipm1_alphas_bar', torch.sqrt(1. / alphas_bar - 1))\n",
        "\n",
        "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        self.register_buffer(\n",
        "            'posterior_var',\n",
        "            self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))\n",
        "        # below: log calculation clipped because the posterior variance is 0 at\n",
        "        # the beginning of the diffusion chain\n",
        "        self.register_buffer(\n",
        "            'posterior_log_var_clipped',\n",
        "            torch.log(\n",
        "                torch.cat([self.posterior_var[1:2], self.posterior_var[1:]])))\n",
        "        self.register_buffer(\n",
        "            'posterior_mean_coef1',\n",
        "            torch.sqrt(alphas_bar_prev) * self.betas / (1. - alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'posterior_mean_coef2',\n",
        "            torch.sqrt(alphas) * (1. - alphas_bar_prev) / (1. - alphas_bar))\n",
        "\n",
        "    def q_mean_variance(self, x_0, x_t, t):\n",
        "        \"\"\"\n",
        "        Compute the mean and variance of the diffusion posterior\n",
        "        q(x_{t-1} | x_t, x_0)\n",
        "        \"\"\"\n",
        "        assert x_0.shape == x_t.shape\n",
        "        posterior_mean = (\n",
        "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_0 +\n",
        "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
        "        )\n",
        "        posterior_log_var_clipped = extract(\n",
        "            self.posterior_log_var_clipped, t, x_t.shape)\n",
        "        return posterior_mean, posterior_log_var_clipped\n",
        "\n",
        "    def predict_xstart_from_eps(self, x_t, t, eps):\n",
        "        assert x_t.shape == eps.shape\n",
        "        return (\n",
        "            extract(self.sqrt_recip_alphas_bar, t, x_t.shape) * x_t -\n",
        "            extract(self.sqrt_recipm1_alphas_bar, t, x_t.shape) * eps\n",
        "        )\n",
        "\n",
        "    def predict_xstart_from_xprev(self, x_t, t, xprev):\n",
        "        assert x_t.shape == xprev.shape\n",
        "        return (  # (xprev - coef2*x_t) / coef1\n",
        "            extract(\n",
        "                1. / self.posterior_mean_coef1, t, x_t.shape) * xprev -\n",
        "            extract(\n",
        "                self.posterior_mean_coef2 / self.posterior_mean_coef1, t,\n",
        "                x_t.shape) * x_t\n",
        "        )\n",
        "\n",
        "    def p_mean_variance(self, x_t, condition, t):\n",
        "        # below: only log_variance is used in the KL computations\n",
        "        # model_log_var = {\n",
        "        #     # for fixedlarge, we set the initial (log-)variance like so to\n",
        "        #     # get a better decoder log likelihood\n",
        "        #     'fixedlarge': torch.log(torch.cat([self.posterior_var[1:2],\n",
        "        #                                        self.betas[1:]])),\n",
        "        #     'fixedsmall': self.posterior_log_var_clipped,\n",
        "        # }[self.var_type]\n",
        "        # model_log_var = extract(model_log_var, t, x_t.shape)\n",
        "\n",
        "        # Mean parameterization\n",
        "        if self.mean_type == 'xprev':       # the model predicts x_{t-1}\n",
        "            x_prev = self.model(x_t, t)\n",
        "            x_0 = self.predict_xstart_from_xprev(x_t, t, xprev=x_prev)\n",
        "            model_mean = x_prev\n",
        "        elif self.mean_type == 'xstart':    # the model predicts x_0\n",
        "            x_0 = self.model(x_t, t)\n",
        "            model_mean, _ = self.q_mean_variance(x_0, x_t, t)\n",
        "        elif self.mean_type == 'epsilon':   # the model predicts epsilon\n",
        "            eps = self.model(torch.cat([x_t, condition], dim=1), t)\n",
        "            x_0 = self.predict_xstart_from_eps(x_t, t, eps=eps)\n",
        "            # model_mean, _ = self.q_mean_variance(x_0, x_t, t)\n",
        "        else:\n",
        "            raise NotImplementedError(self.mean_type)\n",
        "        x_0 = torch.clamp(x_0, 0., 1.)\n",
        "        model_mean, model_log_var = self.q_mean_variance(x_0, x_t, t)\n",
        "\n",
        "        return model_mean, model_log_var\n",
        "\n",
        "    def forward(self, x_T, condition):\n",
        "        \"\"\"\n",
        "        Algorithm 2.\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        x_t = x_T\n",
        "        for time_step in reversed(range(self.T)):\n",
        "            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step\n",
        "            mean, log_var = self.p_mean_variance(x_t=x_t, condition=condition, t=t)\n",
        "            # no noise when t == 0\n",
        "            if time_step > 0:\n",
        "                noise = torch.randn_like(x_t)\n",
        "            else:\n",
        "                noise = 0\n",
        "            x_t = mean + torch.exp(0.5 * log_var) * noise\n",
        "\n",
        "            if time_step == (self.T-1):\n",
        "                out.append(x_t)\n",
        "\n",
        "            if time_step % 250 == 0:\n",
        "                out.append(x_t)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "29GQvLPtV6hu"
      },
      "outputs": [],
      "source": [
        "# model.py DDPM folder\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn import functional as F\n",
        "from torchvision import models\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, embed_dim, scale=30.):\n",
        "        super().__init__()\n",
        "        # Randomly sample weights druing initialization. These weights are fixed\n",
        "        # during optimization and are not trainable.\n",
        "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_proj = x[:, None] * self.W[None, :].to(x.device) * 2 * np.pi\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.main.weight)\n",
        "        init.zeros_(self.main.bias)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.main.weight)\n",
        "        init.zeros_(self.main.bias)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        _, _, H, W = x.shape\n",
        "        x = F.interpolate(\n",
        "            x, scale_factor=2, mode='nearest')\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
        "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
        "            init.xavier_uniform_(module.weight)\n",
        "            init.zeros_(module.bias)\n",
        "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.group_norm(x)\n",
        "        q = self.proj_q(h)\n",
        "        k = self.proj_k(h)\n",
        "        v = self.proj_v(h)\n",
        "\n",
        "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        k = k.view(B, C, H * W)\n",
        "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
        "        assert list(w.shape) == [B, H * W, H * W]\n",
        "        w = F.softmax(w, dim=-1)\n",
        "\n",
        "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        h = torch.bmm(w, v)\n",
        "        assert list(h.shape) == [B, H * W, C]\n",
        "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "        h = self.proj(h)\n",
        "\n",
        "        return x + h\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
        "        super().__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(32, in_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        self.temb_proj = nn.Sequential(\n",
        "            Swish(),\n",
        "            nn.Linear(tdim, out_ch),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(32, out_ch),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        if in_ch != out_ch:\n",
        "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        if attn:\n",
        "            self.attn = AttnBlock(out_ch)\n",
        "        else:\n",
        "            self.attn = nn.Identity()\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
        "                init.xavier_uniform_(module.weight)\n",
        "                init.zeros_(module.bias)\n",
        "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        h = self.block1(x) # [batch, out_ch, h, w]\n",
        "        h += self.temb_proj(temb)[:, :, None, None] # [batch, out_ch, :, :]\n",
        "        h = self.block2(h) # [batch, out_ch, h, w]\n",
        "\n",
        "        h = h + self.shortcut(x)\n",
        "        h = self.attn(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
        "        super().__init__()\n",
        "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
        "        tdim = ch * 4\n",
        "        self.time_embedding = TimeEmbedding(tdim)\n",
        "        # self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
        "\n",
        "        self.head = nn.Conv2d(2, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.downblocks = nn.ModuleList()\n",
        "        chs = [ch]  # record output channel when dowmsample for upsample\n",
        "        now_ch = ch\n",
        "        for i, mult in enumerate(ch_mult):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks):\n",
        "                self.downblocks.append(ResBlock(\n",
        "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
        "                    dropout=dropout, attn=False))\n",
        "                now_ch = out_ch\n",
        "                chs.append(now_ch)\n",
        "            if i != len(ch_mult) - 1:\n",
        "                self.downblocks.append(DownSample(now_ch))\n",
        "                chs.append(now_ch)\n",
        "\n",
        "        self.middleblocks = nn.ModuleList([\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
        "        ])\n",
        "\n",
        "        self.upblocks = nn.ModuleList()\n",
        "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks + 1):\n",
        "                self.upblocks.append(ResBlock(\n",
        "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
        "                    dropout=dropout, attn=False))\n",
        "                now_ch = out_ch\n",
        "            if i != 0:\n",
        "                self.upblocks.append(UpSample(now_ch))\n",
        "        assert len(chs) == 0\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            nn.GroupNorm(32, now_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(now_ch, 1, 3, stride=1, padding=1)\n",
        "        )\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        init.xavier_uniform_(self.head.weight)\n",
        "        init.zeros_(self.head.bias)\n",
        "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
        "        init.zeros_(self.tail[-1].bias)\n",
        "\n",
        "    def forward(self, x, t):  # t [batch,], x [batch,3,h,w]\n",
        "        # Timestep embedding\n",
        "        temb = self.time_embedding(t) # [batch, 128*4]\n",
        "        # Downsampling\n",
        "        h = self.head(x) # [batch,128,h,w]\n",
        "        hs = [h]\n",
        "        for layer in self.downblocks: # [res, res, down; res, res, down; res, res, down; res, res]\n",
        "            h = layer(h, temb)\n",
        "            hs.append(h)\n",
        "        # Middle\n",
        "        for layer in self.middleblocks: # [res, res]\n",
        "            h = layer(h, temb)\n",
        "        # Upsampling\n",
        "        for layer in self.upblocks: # [res,res,res; res,res,res,up; res,res,res,up; res,res,res,up]\n",
        "            if isinstance(layer, ResBlock):\n",
        "                h = torch.cat([h, hs.pop()], dim=1)\n",
        "            h = layer(h, temb)\n",
        "        h = self.tail(h)\n",
        "\n",
        "        assert len(hs) == 0\n",
        "        return h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-rXdmYq2V6hv"
      },
      "outputs": [],
      "source": [
        "# train.py DDPM folder\n",
        "import sys\n",
        "import copy\n",
        "import os\n",
        "import warnings\n",
        "import scipy.io as sio\n",
        "from absl import app, flags\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# from diffusion import GaussianDiffusionTrainer, GaussianDiffusionSampler\n",
        "# from model import UNet\n",
        "# from Dataset.dataset import Train_Data, Valid_Data\n",
        "\n",
        "\n",
        "train = True\n",
        "continue_train = False\n",
        "\n",
        "# UNet\n",
        "ch = 64\n",
        "ch_mult = [1, 2, 2, 4, 4]\n",
        "attn = [1]\n",
        "num_res_blocks = 2\n",
        "dropout = 0.\n",
        "\n",
        "# Gaussian Diffusion\n",
        "beta_1 = 1e-4\n",
        "beta_T = 0.02\n",
        "T = 1000\n",
        "\n",
        "# Training\n",
        "lr = 1e-4\n",
        "grad_clip = 1.\n",
        "img_size = 128\n",
        "batch_size = 2\n",
        "num_workers = 1\n",
        "ema_decay = 0.9999\n",
        "\n",
        "sample_size = 1\n",
        "max_epoch = 5000\n",
        "# max_epoch = 1\n",
        "\n",
        "epoch_mean_loss = max_epoch * [None]\n",
        "n_prev_epochs = 20\n",
        "# Logging & Sampling\n",
        "DIREC = f'ddpm-unet_epochs_{max_epoch}_n-train-samples_{n_train_new}_batch-size_{batch_size}_T_{T}_img-size_{img_size}_{k}fold_cross_validation'\n",
        "\n",
        "# device = torch.device('cuda:0')\n",
        "\n",
        "\n",
        "def ema(source, target, decay):\n",
        "    source_dict = source.state_dict()\n",
        "    target_dict = target.state_dict()\n",
        "    for key in source_dict.keys():\n",
        "        target_dict[key].data.copy_(\n",
        "            target_dict[key].data * decay +\n",
        "            source_dict[key].data * (1 - decay))\n",
        "\n",
        "def train(fold):\n",
        "    print(f'start training with fold number {fold}')\n",
        "\n",
        "    # dataset\n",
        "    tr_train = Train_Data(mr_path=f'mr_train_augmented{fold}.hdf5', ct_path=f'ct_train_augmented{fold}.hdf5')\n",
        "    trainloader = DataLoader(tr_train, batch_size=batch_size, num_workers=num_workers,\n",
        "                            pin_memory=True, shuffle=True)\n",
        "    va_train = Valid_Data(mr_path=f'mr_test{fold}.hdf5', ct_path=f'ct_test{fold}.hdf5')\n",
        "    validloader = DataLoader(va_train, batch_size=sample_size, num_workers=num_workers,\n",
        "                              pin_memory=True, shuffle=False)\n",
        "\n",
        "    # model setup\n",
        "    net_model = UNet(\n",
        "        T=T, ch=ch, ch_mult=ch_mult, attn=attn,\n",
        "        num_res_blocks=num_res_blocks, dropout=dropout)\n",
        "    ema_model = copy.deepcopy(net_model)\n",
        "\n",
        "\n",
        "    optim = torch.optim.Adam(net_model.parameters(), lr=lr)\n",
        "\n",
        "    trainer = GaussianDiffusionTrainer(\n",
        "        net_model, beta_1, beta_T, T).to(device)\n",
        "    ema_sampler = GaussianDiffusionSampler(\n",
        "        ema_model, beta_1, beta_T, T, img_size).to(device)\n",
        "\n",
        "\n",
        "    # show model size\n",
        "    model_size = 0\n",
        "    for param in net_model.parameters():\n",
        "        model_size += param.data.nelement()\n",
        "    print('Model params: %.2f M' % (model_size / 1024 / 1024))\n",
        "\n",
        "    if continue_train:\n",
        "        checkpoint = torch.load('./Save/' + DIREC + '/model_latest.pkl', map_location=\"cuda:0\")\n",
        "        net_model.load_state_dict(checkpoint['net_model'])\n",
        "        ema_model.load_state_dict(checkpoint['ema_model'])\n",
        "        optim.load_state_dict(checkpoint['optim'])\n",
        "        restore_epoch = checkpoint['epoch']\n",
        "        print('Finish loading model')\n",
        "    else:\n",
        "        restore_epoch = 0\n",
        "\n",
        "    if not os.path.exists('Loss'):\n",
        "        os.makedirs('Loss')\n",
        "\n",
        "    tr_ls = []\n",
        "    if continue_train:\n",
        "        readmat = sio.loadmat('./Loss/' + DIREC)\n",
        "        load_tr_ls = readmat['loss']\n",
        "        for i in range(restore_epoch):\n",
        "            tr_ls.append(load_tr_ls[0][i])\n",
        "        print('Finish loading loss!')\n",
        "\n",
        "    if not os.path.exists('./diff_results'):\n",
        "        os.makedirs('./diff_results')\n",
        "\n",
        "    for epoch in range(restore_epoch, max_epoch):\n",
        "        with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "            tmp_tr_loss = 0\n",
        "            tr_sample = 0\n",
        "            net_model.train()\n",
        "            for data, target in tepoch:\n",
        "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
        "\n",
        "                # train\n",
        "                optim.zero_grad()\n",
        "                condition = data.to(device)\n",
        "                x_0 = target.to(device)\n",
        "\n",
        "                loss = trainer(x_0, condition)\n",
        "                tmp_tr_loss += loss.item()\n",
        "                tr_sample += len(data)\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    net_model.parameters(), grad_clip)\n",
        "                optim.step()\n",
        "                ema(net_model, ema_model, ema_decay)\n",
        "\n",
        "                tepoch.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "        mean_loss = tmp_tr_loss / tr_sample\n",
        "        print('mean loss', mean_loss)\n",
        "\n",
        "        epoch_mean_loss[epoch] = mean_loss\n",
        "\n",
        "        if epoch > 100:\n",
        "          prev_mean_loss = 0\n",
        "\n",
        "          for i in range(n_prev_epochs):\n",
        "            prev_mean_loss += epoch_mean_loss[epoch - (i+1)]\n",
        "\n",
        "          prev_mean_loss /= n_prev_epochs\n",
        "          # print('number of samples: ', tr_sample)\n",
        "          # print('prev mean loss:', prev_mean_loss)\n",
        "          if mean_loss > (prev_mean_loss - 0.01*prev_mean_loss):\n",
        "            break\n",
        "\n",
        "        tr_ls.append(tmp_tr_loss / tr_sample)\n",
        "        sio.savemat('./Loss/' + DIREC +'.mat', {'loss': tr_ls})\n",
        "\n",
        "        if not os.path.exists('Train_Output/' + DIREC):\n",
        "            os.makedirs('Train_Output/' + DIREC)\n",
        "        net_model.eval()\n",
        "        if ((epoch+1) % 5 == 0) and (epoch+1) >= 80:\n",
        "        # if epoch == 0:\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (data, target) in enumerate(validloader):\n",
        "                    # if batch_idx == 0:\n",
        "                        x_T = torch.randn(sample_size, 1, img_size, img_size)\n",
        "                        x_T = x_T.to(device)\n",
        "\n",
        "                        condition = data.to(device)\n",
        "                        x_0 = ema_sampler(x_T, condition)\n",
        "\n",
        "                        diff_out = x_0[-1]\n",
        "                        diff_out = np.array(diff_out.cpu())\n",
        "\n",
        "                        # x_0_copy = len(x_0) * [None]\n",
        "\n",
        "                        # for i, img in enumerate(x_0):\n",
        "                        #     img = np.array(img.cpu())\n",
        "                        #     x_0_copy[i] = img\n",
        "\n",
        "                        # x_0_copy = np.array(x_0_copy)\n",
        "                        if not os.path.exists(f'./diff_results/fold{fold}'):\n",
        "                          os.makedirs(f'./diff_results/fold{fold}')\n",
        "                        save_path = f'./diff_results/fold{fold}/x0_number_{batch_idx+1}_epoch_{epoch+1}.npy'\n",
        "                        np.save(save_path, diff_out)\n",
        "\n",
        "                        # fig = plt.figure()\n",
        "                        # fig.set_figheight(8)\n",
        "                        # fig.set_figwidth(28)\n",
        "                        # spec = gridspec.GridSpec(ncols=7, nrows=2,\n",
        "                        #       width_ratios=[1,1,1,1,1,1,1], wspace=0.01,\n",
        "                        #       hspace=0.01, height_ratios=[1,1],left=0,right=1,top=1,bottom=0)\n",
        "\n",
        "                        # img = data[0].data.squeeze()\n",
        "                        # ax = fig.add_subplot(spec[0])\n",
        "                        # ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        # ax.axis('off')\n",
        "                        # # img = data[1].data.squeeze()\n",
        "                        # # ax = fig.add_subplot(spec[7])\n",
        "                        # # ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        # # ax.axis('off')\n",
        "\n",
        "                        # count = 1\n",
        "                        # for kk in range(5): # x_0 [5,b,1,h,w]\n",
        "                        #     imgs = x_0[kk] # imgs [b,1,h,w]\n",
        "                        #     img = imgs[0].data.squeeze().cpu()\n",
        "                        #     ax = fig.add_subplot(spec[count])\n",
        "                        #     ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        #     ax.axis('off')\n",
        "\n",
        "                        #     # imgs = x_0[kk] # imgs [b,1,h,w]\n",
        "                        #     # img = imgs[1].data.squeeze().cpu()\n",
        "                        #     # ax = fig.add_subplot(spec[count+7])\n",
        "                        #     # ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        #     # ax.axis('off')\n",
        "\n",
        "                        #     count += 1\n",
        "\n",
        "                        # img = target[0].data.squeeze().cpu()\n",
        "                        # ax = fig.add_subplot(spec[6])\n",
        "                        # ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        # ax.axis('off')\n",
        "                        # # img = target[1].data.squeeze().cpu()\n",
        "                        # # ax = fig.add_subplot(spec[13])\n",
        "                        # # ax.imshow(img, cmap='gray', vmin=0,vmax=1)\n",
        "                        # # ax.axis('off')\n",
        "\n",
        "                        plt.savefig('./Train_Output/'+ DIREC + '/Epoch_' + str(epoch+1) + '.png',\n",
        "                                    bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "                        # if not os.path.exists('Saved_model'):\n",
        "                        #    os.makedirs('Saved_model')\n",
        "\n",
        "                        # torch.save(ema_model.state_dict(), f'./Saved_model/ema_model_epoch_{epoch+1}.pt')\n",
        "\n",
        "        # # save\n",
        "        # if not os.path.exists('Save/' + DIREC):\n",
        "        #     os.makedirs('Save/' + DIREC)\n",
        "        # ckpt = {\n",
        "        #     'net_model': net_model.state_dict(),\n",
        "        #     'ema_model': ema_model.state_dict(),\n",
        "        #     'optim': optim.state_dict(),\n",
        "        #     'epoch': epoch+1,\n",
        "        #     # 'x_T': x_T,\n",
        "        # }\n",
        "        # if (epoch+1) % 2 == 0:\n",
        "        #     torch.save(ckpt, './Save/' + DIREC + '/model_epoch_'+str(epoch+1)+'.pkl')\n",
        "        # torch.save(ckpt, './Save/' + DIREC + '/model_latest.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(fold=1)\n",
        "# train(fold=2)\n",
        "# train(fold=3)\n",
        "# train(fold=4)\n",
        "# train(fold=5)"
      ],
      "metadata": {
        "id": "KmCvRflhIDXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aca8a581-cf4c-4aef-f3d6-ca83e66ee014"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start training with fold number 1\n",
            "Model params: 24.91 M\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 800/800 [02:01<00:00,  6.60batch/s, Loss=0.00659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.031583229691314045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.0124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.004729625778818445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.00127]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.004034085877956386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00608]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.003955395894627145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 800/800 [01:50<00:00,  7.26batch/s, Loss=0.00113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.003502561546101788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 800/800 [01:51<00:00,  7.17batch/s, Loss=0.00194]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0028635326533549233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 800/800 [01:51<00:00,  7.20batch/s, Loss=0.0389]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.003282785247774882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 800/800 [01:50<00:00,  7.27batch/s, Loss=0.002]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0030446499165373096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.0201]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0026268359334790147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 800/800 [01:48<00:00,  7.34batch/s, Loss=0.00321]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.002866665845795069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.00186]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0026417492241671424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.0128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0023039758836966937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 800/800 [01:47<00:00,  7.43batch/s, Loss=0.00622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0024977922707239484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 800/800 [01:48<00:00,  7.39batch/s, Loss=0.000402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0025094495856683354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 800/800 [01:48<00:00,  7.40batch/s, Loss=0.00208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0023804175631084944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.000518]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.002020537058942864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.000729]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0024312711718266653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 800/800 [01:47<00:00,  7.42batch/s, Loss=0.000522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0018258366503050639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.000643]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0022498922423073962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.000402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0019968558058644703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 800/800 [01:48<00:00,  7.39batch/s, Loss=0.000345]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0019891129445750266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 800/800 [01:48<00:00,  7.41batch/s, Loss=0.000331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001975130588589309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.0148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0017294887246862346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0019532144355616766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00107]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0018645953183659004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000436]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0020258101488980175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00081]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0018269308419166918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 800/800 [01:48<00:00,  7.39batch/s, Loss=0.000451]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001807856478562826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001825720639071733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0017454032352543435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.00044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013861087388795568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.000885]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016383030939232412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.00151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001830481382689868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.000212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016369381387767135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016922141469740382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.00117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016102516536602707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.00657]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0017417962085619365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.00114]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001482838370943682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 800/800 [01:47<00:00,  7.41batch/s, Loss=0.00811]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0018518234150542412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 800/800 [01:48<00:00,  7.40batch/s, Loss=0.00209]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016218706665813442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.000865]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015282519900347324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.000426]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015755365500399422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.00044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001523303777748879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00142]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001390840940516682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.0003]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014794752286479706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001547832161822953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47: 100%|██████████| 800/800 [01:50<00:00,  7.25batch/s, Loss=0.00121]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0018479745287413606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48: 100%|██████████| 800/800 [01:50<00:00,  7.27batch/s, Loss=0.000193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014754251098474925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.00659]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015835173780124024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00054]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0016466270042928954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.00288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012378155562782923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015370240016773097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.00166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014859065223936342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.000132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001401144995870709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.000614]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012716131173101531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015781116046082388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.0191]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012482302352646002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58: 100%|██████████| 800/800 [01:49<00:00,  7.31batch/s, Loss=0.000974]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014015886522338406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.00279]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.00157955857372599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013676135065770723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.00254]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010880711351865101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00287]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001231965436027167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63: 100%|██████████| 800/800 [01:49<00:00,  7.31batch/s, Loss=0.00511]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013053250638381541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00544]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001381773586726922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65: 100%|██████████| 800/800 [01:48<00:00,  7.37batch/s, Loss=0.000722]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001425995081272049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.000839]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013890524118005487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67: 100%|██████████| 800/800 [01:48<00:00,  7.38batch/s, Loss=0.000205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001323027258968068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000912]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012071682253554173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00219]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014212194270612599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.000366]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012778461055677325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.00106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001242113324510683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72: 100%|██████████| 800/800 [01:48<00:00,  7.34batch/s, Loss=0.000216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014190511218066604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.000778]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013343489832277555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011574659725556557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=8.8e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010258716996168005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.0156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013259334536519418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77: 100%|██████████| 800/800 [01:48<00:00,  7.39batch/s, Loss=0.000151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011594276727873876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.000292]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001300042165235027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000587]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010517346135293338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.00259]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001214828489771662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 81: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.000211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0009792119263443055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000669]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.001406734066486024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000469]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011837985133229267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84: 100%|██████████| 800/800 [01:51<00:00,  7.18batch/s, Loss=0.000145]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011476985758508817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85: 100%|██████████| 800/800 [01:51<00:00,  7.17batch/s, Loss=0.00101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0009290449966329106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=0.000687]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012200329307165702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87: 100%|██████████| 800/800 [01:48<00:00,  7.35batch/s, Loss=0.00324]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0012119993902570058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=0.00199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013674698200929925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000228]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010473418119795496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90: 100%|██████████| 800/800 [01:49<00:00,  7.28batch/s, Loss=0.000254]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0009384692776848169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 91: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.00013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010473756523288102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92: 100%|██████████| 800/800 [01:50<00:00,  7.26batch/s, Loss=0.000672]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0015553222114590426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93: 100%|██████████| 800/800 [01:49<00:00,  7.34batch/s, Loss=9.65e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011574864444219202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.000426]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.000984327060286887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.000144]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0009213144921318417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 96: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.00156]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011504291293840652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97: 100%|██████████| 800/800 [01:49<00:00,  7.33batch/s, Loss=0.000308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0013712658331223792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98: 100%|██████████| 800/800 [01:49<00:00,  7.32batch/s, Loss=0.000609]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0010223376686144547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99: 100%|██████████| 800/800 [01:48<00:00,  7.36batch/s, Loss=9.44e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011910777747607426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100: 100%|██████████| 800/800 [01:49<00:00,  7.29batch/s, Loss=0.000429]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011533386863038686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 101: 100%|██████████| 800/800 [01:46<00:00,  7.53batch/s, Loss=0.000182]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0011338361081448057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 102: 100%|██████████| 800/800 [01:49<00:00,  7.30batch/s, Loss=0.000337]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean loss 0.0014318019118309167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_test_new = fold_size"
      ],
      "metadata": {
        "id": "I8I9lyomRWID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e567bf5-9a44-4530-95eb-14ff662b4a57"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1hOEdHjFV6hw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "6aa4f528-a443-4465-d3c1-95579103db5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epoch = 100\n",
        "diff_outs = [None] * n_test_new\n",
        "fold = 1\n",
        "\n",
        "for i in range(n_test_new):\n",
        "  diff_out = np.load(f'./diff_results/fold{fold}/x0_number_{i+1}_epoch_{epoch}.npy')\n",
        "  diff_out = np.reshape(diff_out, (img_size, img_size, 1))\n",
        "  plt.imshow(diff_out, cmap='gray')\n",
        "  # diff_out = np.reshape(diff_out, (1, img_size, img_size))\n",
        "  # diff_out = torch.tensor(diff_out)\n",
        "  # diff_outs[i] = diff_out.unsqueeze(0)\n",
        "\n",
        "\n",
        "path = f'ct_test{fold}.hdf5'\n",
        "f = h5py.File(path,'r')\n",
        "ct_test_fold = f['data']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pytorch-ignite"
      ],
      "metadata": {
        "id": "JAymPRy3tWti"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "EbQ9sTC9V6hw"
      },
      "outputs": [],
      "source": [
        "from ignite.metrics import PSNR, SSIM\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "from ignite.engine import *\n",
        "from ignite.handlers import *\n",
        "from ignite.metrics import *\n",
        "from ignite.utils import *\n",
        "from ignite.contrib.metrics.regression import *\n",
        "from ignite.contrib.metrics import *\n",
        "\n",
        "# create default evaluator for doctests\n",
        "\n",
        "def eval_step(engine, batch):\n",
        "    return batch\n",
        "\n",
        "default_evaluator = Engine(eval_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UHb7PonYV6hw"
      },
      "outputs": [],
      "source": [
        "targets = [None] * n_test_new\n",
        "\n",
        "for i in range(n_test_new):\n",
        "  ct_sample = ct_test_fold[i]\n",
        "  ct_sample = np.reshape(ct_sample, (1, img_size, img_size))\n",
        "  ct_sample = torch.tensor(ct_sample)\n",
        "  targets[i] = ct_sample.unsqueeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vvDAs8dlV6hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e92c8c2-7c48-4361-f75f-066448e0e79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7576877817916952\n",
            "0.8786321989105628\n",
            "0.6699464118489906\n",
            "0.6633016977424009\n",
            "0.5785646019706157\n",
            "0.5791178351204944\n",
            "0.8534248386369652\n",
            "0.7666755865992005\n",
            "0.6983905736118386\n",
            "0.7200167001587716\n"
          ]
        }
      ],
      "source": [
        "metric = SSIM(data_range=1.0)\n",
        "metric.attach(default_evaluator, 'ssim')\n",
        "\n",
        "\n",
        "sum_ssims = 0\n",
        "\n",
        "for i in range(n_test_new):\n",
        "  state = default_evaluator.run([[diff_outs[i], targets[i]]])\n",
        "  ssim_value = state.metrics['ssim']\n",
        "  print(ssim_value)\n",
        "  sum_ssims += ssim_value\n",
        "\n",
        "avg_ssim = sum_ssims / n_test_new\n",
        "\n",
        "# avg_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7ZRIRyxV6hx"
      },
      "outputs": [],
      "source": [
        "# average\n",
        "\n",
        "80: 0.58\n",
        "85: 0.61\n",
        "90: 0.61\n",
        "95: 0.58\n",
        "100: 0.71"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1PGFmOqSVYZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}