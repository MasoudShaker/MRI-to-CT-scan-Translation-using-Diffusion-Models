{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFcWuxXb_adA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "from model import UNet\n",
        "import h5py\n",
        "\n",
        "from utils import get_ssim, get_psnr, get_mse, get_mae, save_metrics, pre_process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E8JQ9KoK_adC",
        "outputId": "f04e6dd4-a6a2-48b9-8dd1-8f029d1b299d"
      },
      "outputs": [],
      "source": [
        "img_size = 128\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'ct_test_resized.hdf5'\n",
        "f = h5py.File(path,'r')\n",
        "ct_test = f['data']\n",
        "ct_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_size = ct_test.shape[0]\n",
        "test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T93I0Sl9AtWA"
      },
      "outputs": [],
      "source": [
        "# configs\n",
        "\n",
        "class data(object):\n",
        "  def __init__(self):\n",
        "    self.dataset = \"CELEBA\"\n",
        "    self.image_size = 128\n",
        "    self.channels = 1\n",
        "    self.logit_transform = False\n",
        "    self.uniform_dequantization = False\n",
        "    self.gaussian_dequantization = False\n",
        "    self.random_flip = True\n",
        "    self.rescaled = True\n",
        "    self.num_workers = 4\n",
        "\n",
        "class model(object):\n",
        "  def __init__(self):\n",
        "    self.var_type = \"fixedlarge\"\n",
        "\n",
        "class diffusion(object):\n",
        "  def __init__(self):\n",
        "    self.beta_schedule = \"linear\"\n",
        "    self.beta_start = 0.0001\n",
        "    self.beta_end = 0.02\n",
        "    self.num_diffusion_timesteps = 1000\n",
        "\n",
        "\n",
        "class sampling(object):\n",
        "  def __init__(self):\n",
        "    self.batch_size = 1\n",
        "    self.last_only = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B0XPwDTe9uq"
      },
      "outputs": [],
      "source": [
        "class args(object):\n",
        "  def __init__(self):\n",
        "    self.eta = 0 # 0 is DDIM, and 1 is one type of DDPM\n",
        "    self.skip = 2\n",
        "    self.skip_type = \"uniform\"\n",
        "    self.sample_type = \"generalized\"\n",
        "    self.timesteps = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVr4Kg3hLFVB"
      },
      "outputs": [],
      "source": [
        "config_data = data()\n",
        "config_model = model()\n",
        "config_diffusion = diffusion()\n",
        "config_sampling = sampling()\n",
        "args = args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxWpydVw_7oK"
      },
      "outputs": [],
      "source": [
        "# diffusion.py\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.utils as tvu\n",
        "\n",
        "max_epoch = 101\n",
        "\n",
        "# utils\n",
        "\n",
        "\n",
        "def compute_alpha(beta, t):\n",
        "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
        "    a = (1 - beta).cumprod(dim=0).index_select(0, t + 1).view(-1, 1, 1, 1)\n",
        "    return a\n",
        "\n",
        "\n",
        "\n",
        "def inverse_data_transform(X):\n",
        "\n",
        "    if config_data.logit_transform:\n",
        "        X = torch.sigmoid(X)\n",
        "    elif config_data.rescaled:\n",
        "        X = (X + 1.0) / 2.0\n",
        "\n",
        "    return torch.clamp(X, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def torch2hwcuint8(x, clip=False):\n",
        "    if clip:\n",
        "        x = torch.clamp(x, -1, 1)\n",
        "    x = (x + 1.0) / 2.0\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_beta_schedule(beta_schedule, *, beta_start, beta_end, num_diffusion_timesteps):\n",
        "    def sigmoid(x):\n",
        "        return 1 / (np.exp(-x) + 1)\n",
        "\n",
        "    if beta_schedule == \"quad\":\n",
        "        betas = (\n",
        "            np.linspace(\n",
        "                beta_start ** 0.5,\n",
        "                beta_end ** 0.5,\n",
        "                num_diffusion_timesteps,\n",
        "                dtype=np.float64,\n",
        "            )\n",
        "            ** 2\n",
        "        )\n",
        "    elif beta_schedule == \"linear\":\n",
        "        betas = np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"const\":\n",
        "        betas = beta_end * np.ones(num_diffusion_timesteps, dtype=np.float64)\n",
        "    elif beta_schedule == \"jsd\":  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
        "        betas = 1.0 / np.linspace(\n",
        "            num_diffusion_timesteps, 1, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "    elif beta_schedule == \"sigmoid\":\n",
        "        betas = np.linspace(-6, 6, num_diffusion_timesteps)\n",
        "        betas = sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
        "    else:\n",
        "        raise NotImplementedError(beta_schedule)\n",
        "    assert betas.shape == (num_diffusion_timesteps,)\n",
        "    return betas\n",
        "\n",
        "\n",
        "\n",
        "def generalized_steps(x, seq, model, b, condition, eta):\n",
        "    with torch.no_grad():\n",
        "        n = x.size(0)\n",
        "        seq_next = [-1] + list(seq[:-1])\n",
        "        x0_preds = []\n",
        "        xs = [x]\n",
        "        condition = torch.tensor(condition)\n",
        "        condition = condition.unsqueeze(0)\n",
        "        condition = condition.unsqueeze(0)\n",
        "        condition = condition.to('cuda')\n",
        "\n",
        "        for i, j in zip(reversed(seq), reversed(seq_next)):\n",
        "            t = (torch.ones(n) * i).to(x.device)\n",
        "            next_t = (torch.ones(n) * j).to(x.device)\n",
        "            at = compute_alpha(b, t.long())\n",
        "            at_next = compute_alpha(b, next_t.long())\n",
        "            xt = xs[-1].to('cuda')\n",
        "            # print(f'xt shape:{xt.shape}')\n",
        "            # print(f't shape:{t.shape}')\n",
        "\n",
        "            # print(xt.is_cuda)\n",
        "\n",
        "            model = model.to('cuda')\n",
        "\n",
        "            # print(f'xt shape: {xt.shape}')\n",
        "            # print(f'condition shape: {condition.shape}')\n",
        "\n",
        "            et = model(torch.cat([xt, xt], dim=1), t)\n",
        "\n",
        "            # print(f'et:{et}')\n",
        "            # break\n",
        "\n",
        "            x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
        "            x0_preds.append(x0_t.to('cpu'))\n",
        "            c1 = (\n",
        "                eta * ((1 - at / at_next) * (1 - at_next) / (1 - at)).sqrt()\n",
        "            )\n",
        "            c2 = ((1 - at_next) - c1 ** 2).sqrt()\n",
        "            xt_next = at_next.sqrt() * x0_t + c1 * torch.randn_like(x) + c2 * et\n",
        "            xs.append(xt_next.to('cpu'))\n",
        "\n",
        "    return xs, x0_preds\n",
        "\n",
        "\n",
        "class Diffusion(object):\n",
        "    def __init__(self,device=None):\n",
        "        self.args = args\n",
        "        if device is None:\n",
        "            device = (\n",
        "                torch.device(\"cuda\")\n",
        "                if torch.cuda.is_available()\n",
        "                else torch.device(\"cpu\")\n",
        "            )\n",
        "        self.device = device\n",
        "\n",
        "        self.model_var_type = config_model.var_type\n",
        "        betas = get_beta_schedule(\n",
        "            beta_schedule=config_diffusion.beta_schedule,\n",
        "            beta_start=config_diffusion.beta_start,\n",
        "            beta_end=config_diffusion.beta_end,\n",
        "            num_diffusion_timesteps=config_diffusion.num_diffusion_timesteps,\n",
        "        )\n",
        "        betas = self.betas = torch.from_numpy(betas).float().to(self.device)\n",
        "        self.num_timesteps = betas.shape[0]\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cumprod = alphas.cumprod(dim=0)\n",
        "        alphas_cumprod_prev = torch.cat(\n",
        "            [torch.ones(1).to(device), alphas_cumprod[:-1]], dim=0\n",
        "        )\n",
        "        posterior_variance = (\n",
        "            betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "        )\n",
        "        if self.model_var_type == \"fixedlarge\":\n",
        "            self.logvar = betas.log()\n",
        "            # torch.cat(\n",
        "            # [posterior_variance[1:2], betas[1:]], dim=0).log()\n",
        "        elif self.model_var_type == \"fixedsmall\":\n",
        "            self.logvar = posterior_variance.clamp(min=1e-20).log()\n",
        "\n",
        "\n",
        "\n",
        "    def sample_fid(self, model, conditions):\n",
        "        # img_id = len(glob.glob(f\"{self.args.image_folder}/*\"))\n",
        "        img_id = 0\n",
        "        print(f\"starting from image {0}\")\n",
        "        n_rounds = (test_size - img_id) // config_sampling.batch_size\n",
        "\n",
        "        i = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in tqdm.tqdm(\n",
        "                range(n_rounds), desc=\"Generating image samples for FID evaluation.\"\n",
        "            ):\n",
        "                n = config_sampling.batch_size\n",
        "                x = torch.randn(\n",
        "                    n,\n",
        "                    config_data.channels,\n",
        "                    config_data.image_size,\n",
        "                    config_data.image_size,\n",
        "                    device=self.device,\n",
        "                )\n",
        "\n",
        "                condition = conditions[i]\n",
        "\n",
        "                # self.sample_image(x, model, condition)\n",
        "\n",
        "                x = self.sample_image(x, model, condition)\n",
        "                x = inverse_data_transform(x)\n",
        "\n",
        "                path = './current experiment/ddim_results'\n",
        "\n",
        "                if not os.path.exists(path):\n",
        "                  os.makedirs(path)\n",
        "\n",
        "                for j in range(n):\n",
        "                    ddim_result = x[j].unsqueeze(0)\n",
        "                    ddim_result = np.array(ddim_result)\n",
        "\n",
        "                    save_path = f'./current experiment/ddim_results/x0_number_{i+1}_epoch_{max_epoch}.npy'\n",
        "                    np.save(save_path, ddim_result)\n",
        "                    # print(ddim_result.shape)\n",
        "                    # tvu.save_image(\n",
        "                    #     x[i], os.path.join(self.args.image_folder, f\"{img_id}.png\")\n",
        "                    # )\n",
        "                    img_id += 1\n",
        "\n",
        "                i += 1\n",
        "\n",
        "\n",
        "    def sample_image(self, x, model, condition, last=True):\n",
        "        try:\n",
        "            skip = self.args.skip\n",
        "        except Exception:\n",
        "            skip = 1\n",
        "\n",
        "        if self.args.sample_type == \"generalized\":\n",
        "            if self.args.skip_type == \"uniform\":\n",
        "                skip = self.num_timesteps // self.args.timesteps\n",
        "                seq = range(0, self.num_timesteps, skip)\n",
        "            elif self.args.skip_type == \"quad\":\n",
        "                seq = (\n",
        "                    np.linspace(\n",
        "                        0, np.sqrt(self.num_timesteps * 0.8), self.args.timesteps\n",
        "                    )\n",
        "                    ** 2\n",
        "                )\n",
        "                seq = [int(s) for s in list(seq)]\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "            # generalized_steps(x, seq, model, self.betas, condition, eta=self.args.eta)\n",
        "            xs = generalized_steps(x, seq, model, self.betas, condition, eta=self.args.eta)\n",
        "            x = xs\n",
        "\n",
        "        if last:\n",
        "            x = x[1][-1]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukDDiAIUBHe6",
        "outputId": "cff54112-cf6a-483f-c75b-42be77a5602a"
      },
      "outputs": [],
      "source": [
        "# UNet\n",
        "ch = 64\n",
        "ch_mult = [1, 2, 2, 4, 4]\n",
        "attn = [1]\n",
        "num_res_blocks = 2\n",
        "dropout = 0.\n",
        "\n",
        "# Gaussian Diffusion\n",
        "beta_1 = 1e-4\n",
        "beta_T = 0.02\n",
        "T = 1000\n",
        "\n",
        "net_model = UNet(\n",
        "        T=T, ch=ch, ch_mult=ch_mult, attn=attn,\n",
        "        num_res_blocks=num_res_blocks, dropout=dropout)\n",
        "\n",
        "ema_model = copy.deepcopy(net_model)\n",
        "\n",
        "model_path = f'./current experiment/Saved_model/ddpm-unet_epoch_102.pt'\n",
        "\n",
        "ema_model.load_state_dict(torch.load(model_path))\n",
        "ema_model.eval()\n",
        "\n",
        "diffusion = Diffusion()\n",
        "diffusion.sample_fid(ema_model, conditions=ct_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum_time_ddim = 1231\n",
        "\n",
        "avg_time_ddim = sum_time_ddim / test_size\n",
        "\n",
        "avg_time_ddim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diff_outs = [None] * test_size\n",
        "\n",
        "for i in range(test_size):\n",
        "\n",
        "  path = f'./current experiment/ddim_results/x0_number_{i+1}_epoch_{max_epoch}.npy'\n",
        "  diff_out = np.load(path)\n",
        "  diff_outs[i] = pre_process(diff_out, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets = [None] * test_size\n",
        "\n",
        "for i in range(test_size):\n",
        "  ct_sample = ct_test[i]\n",
        "  targets[i] = pre_process(ct_sample, img_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_ssim, argmax_ssim, avg_ssim = get_ssim(diff_outs, targets)\n",
        "max_psnr, argmax_psnr, avg_psnr = get_psnr(diff_outs, targets)\n",
        "\n",
        "min_mse, argmin_mse, avg_mse = get_mse(diff_outs, targets)\n",
        "min_mae, argmin_mae, avg_mae = get_mae(diff_outs, targets)\n",
        "\n",
        "save_metrics(avg_time_ddim, avg_ssim, avg_psnr, avg_mse, avg_mae, max_ssim, max_psnr, min_mse, min_mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "if not os.path.exists('./current experiment/Train_Output/'):\n",
        "    os.makedirs('./current experiment/Train_Output/')\n",
        "\n",
        "\n",
        "best_ssim_folder_path = './current experiment/best ssim'\n",
        "best_psnr_folder_path ='./current experiment/best psnr'\n",
        "best_mse_folder_path ='./current experiment/best mse'\n",
        "best_mae_folder_path ='./current experiment/best mae'\n",
        "\n",
        "os.makedirs(best_ssim_folder_path)\n",
        "os.makedirs(best_psnr_folder_path)\n",
        "os.makedirs(best_mse_folder_path)\n",
        "os.makedirs(best_mae_folder_path)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_ssim_diff_out = diff_outs[argmax_ssim]\n",
        "best_psnr_diff_out = diff_outs[argmax_psnr]\n",
        "best_mse_diff_out = diff_outs[argmin_mse]\n",
        "best_mae_diff_out = diff_outs[argmin_mae]\n",
        "\n",
        "best_ssim_target = targets[argmax_ssim]\n",
        "best_psnr_target = targets[argmax_psnr]\n",
        "best_mse_target = targets[argmin_mse]\n",
        "best_mae_target = targets[argmin_mae]\n",
        "\n",
        "\n",
        "np.save(os.path.join(best_ssim_folder_path, f'diff_out_{argmax_ssim}'), best_ssim_diff_out)\n",
        "np.save(os.path.join(best_ssim_folder_path, f'target_{argmax_ssim}'), best_ssim_target)\n",
        "\n",
        "np.save(os.path.join(best_psnr_folder_path, f'diff_out_{argmax_psnr}'), best_psnr_diff_out)\n",
        "np.save(os.path.join(best_psnr_folder_path, f'target_{argmax_psnr}'), best_psnr_target)\n",
        "\n",
        "np.save(os.path.join(best_mse_folder_path, f'diff_out_{argmin_mse}'), best_mse_diff_out)\n",
        "np.save(os.path.join(best_mse_folder_path, f'target_{argmin_mse}'), best_mse_target)\n",
        "\n",
        "np.save(os.path.join(best_mae_folder_path, f'diff_out_{argmin_mae}'), best_mae_diff_out)\n",
        "np.save(os.path.join(best_mae_folder_path, f'target_{argmin_mae}'), best_mae_target)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
